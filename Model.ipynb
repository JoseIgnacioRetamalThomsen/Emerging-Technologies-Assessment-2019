{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainig a Model Using the MNIST datase for recgonise hand-writen digits\n",
    "    On this notebook we show how to create a model using  MNIST dataset.\n",
    "    We start showing how to read the bits from the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "\n",
    "  We will start by undertandig how the data is formated and parsing it i a suuitable way for train our model.\n",
    "  \n",
    "  Mnist provide 4 files: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Little and Big Endian Architecture \n",
    "\n",
    "  There are 2 types of processors architecture(litle and big endian). In litle endian bits are store from left to righ This is basically how the bytes are stored, in litle they are stored from left to right and in big the other way around.(Look this is you want to know more about https://chortle.ccsu.edu/AssemblyTutorial/Chapter-15/ass15_3.html ).\n",
    "  This is relevant for us because we need to know read the bytes right for get the proper data.\n",
    "  In python we can easyle check using sys, since I am using a Intel processor i expected to be litle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sys import byteorder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check  our architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "little\n"
     ]
    }
   ],
   "source": [
    "print(byteorder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Mnist\n",
    "    Now we can start reading the train images file. \n",
    "    For the tain images we espected (this data can be found in the Mnist website).\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "with gzip.open('mnist/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    fc_train_img = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The first 4 bytes is the magic number which is a 32 bit integer, for the image set this number is 2051. Note that we are setting the byteorder as big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2051"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(fc_train_img[0:4], byteorder='big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Next is the the number of images as a 32 bit integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_total = int.from_bytes(fc_train_img[4:8], byteorder='big')\n",
    "train_img_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then number of rows as 32 bit integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = int.from_bytes(fc_train_img[8:12], byteorder='big')\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a columns as 32 bit integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = int.from_bytes(fc_train_img[12:16], byteorder='big')\n",
    "col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then unsigned bytes(8 bits) , each byte represent a pixel. They are orginezed row-wise.\n",
    "\n",
    "The total of bits is : \n",
    "```python\n",
    "train_img_total*row*col\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47040016"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_byte = (train_img_total*row*col) + 16\n",
    "last_byte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now whe can read all bits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = list(fc_train_img[16:last_byte])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And reshape them ass 28*27 (784) array. They represent our vector.\n",
    "\n",
    "Also in Mnist pixel values are 0 to 255.0 , 0 representing the background. We want ot invert this, because having a non zero value as background is better for the trainig. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = ~np.array(x_train).reshape(train_img_total,row*col).astype(np.uint8)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see one image using pyplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cce1bdb3c8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[11].reshape(row,col), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thats look like the image 11 is a 5. We can now read labels and check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('mnist/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    fc_train_lbl = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 32 bits are magin number : 2049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2049"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(fc_train_lbl[0:4], byteorder='big')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a 32 bits intiger, the total of labels. Must be 6000 as we got 6000 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lvl_total = int.from_bytes(fc_train_lbl[4:8], byteorder='big')\n",
    "train_lvl_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each unsigned byte is a label, so we can check that 11 is 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(list(fc_train_lbl[8:train_lvl_total+8]))\n",
    "print(y_train[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now real the test images and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('mnist/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    fc_test_img = f.read()\n",
    "with gzip.open('mnist/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    fc_test_lbl = f.read()\n",
    "    \n",
    "test_img_total = int.from_bytes(fc_test_img[4:8], byteorder='big')\n",
    "test_lbl_total = int.from_bytes(fc_test_lbl[4:8], byteorder='big')\n",
    "\n",
    "last_byte = (test_img_total*row*col) + 16\n",
    "x_test = list(fc_test_img[16:last_byte])\n",
    "x_test = ~np.array(x_test).reshape(test_img_total,row*col).astype(np.uint8)\n",
    "\n",
    "y_test = np.array(list(fc_test_lbl[8:test_lbl_total+8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train =  x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cce1bea488>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[11].reshape(row,col), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(y_test[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as kr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kr.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(kr.layers.Dense(units=10, input_dim=784, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation : softmax\n",
    "  We want our result to represent a probablility of being one of the 10 digits(0,1,3...).\n",
    "  The softmax activation function will do this for us, it will output our output for each neuron beetwen 0 and 1.Then each \n",
    "  of our neuron can represent a a digit so the one will bigger probability will be our prediction.\n",
    "  \n",
    "  $$\\sigma (z)_j = \\frac{e^{(z)_j}}{\\sum_{k=0}^{K}e^{(z)_k}} \\text{  where   j = 1,...,K}$$  \n",
    "  \n",
    "  In our case K = 10.\n",
    "  \n",
    "  https://www.analyticsvidhya.com/blog/2017/10/fundamentals-deep-learning-activation-functions-when-to-use-them/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.arange(0.0, 784, 1).reshape(1,784)\n",
    "result = model.predict(test)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = 0 \n",
    "for i in result[0]:\n",
    "    sum += i\n",
    "sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss : categorical_crossentropy\n",
    "\n",
    "    After we calculate our result we need to calculate the distance beetween our prediction and our epected result.\n",
    "    https://algorithmia.com/blog/introduction-to-loss-functions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimazer : adam\n",
    "https://algorithmia.com/blog/introduction-to-optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = kr.utils.to_categorical(y_train, 10)\n",
    "y_test  = kr.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 0.8151 - accuracy: 0.7825 - val_loss: 0.4413 - val_accuracy: 0.8842\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "history_callback = model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=epoch, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = np.array(history_callback.history['val_accuracy'])\n",
    "val_loss =  np.array(history_callback.history['val_loss'])\n",
    "accuracy =  np.array(history_callback.history['accuracy'])\n",
    "loss =  np.array(history_callback.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1caa5533788>,\n",
       " <matplotlib.lines.Line2D at 0x1caa553a688>,\n",
       " <matplotlib.lines.Line2D at 0x1caa553a848>,\n",
       " <matplotlib.lines.Line2D at 0x1caa553aa08>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.0, epoch, 1)\n",
    "plt.plot(x,val_accuracy,x,accuracy,x,loss,x,val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModelCheckpoint(kr.callbacks.Callback):\n",
    "    minimun = 0.99\n",
    "   \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        score = self.model.evaluate(x_test, y_test, verbose=0)\n",
    "        # logs is a dictionary\n",
    "        print(f\"epoch: {epoch},history_callback.{logs['val_accuracy']}\")\n",
    "        print(score[1])\n",
    "        if score[1] > self.minimun: # your custom condition\n",
    "    \n",
    "            self.model.save('model7.h5', overwrite=True)\n",
    "           \n",
    "            print(\"saved\")\n",
    "            \n",
    "           \n",
    "            \n",
    "            self.minimun = score[1]\n",
    "            print(self.minimun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.4282 - accuracy: 0.8800 - val_loss: 0.3694 - val_accuracy: 0.8938\n",
      "epoch: 0,history_callback.0.8938000202178955\n",
      "0.8938000202178955\n"
     ]
    }
   ],
   "source": [
    "cbk = CustomModelCheckpoint()\n",
    "history_callback = model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=epoch, batch_size=100, callbacks=[cbk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kr.models.Sequential()\n",
    "model.add(kr.layers.Dense(units=512, input_dim=784, activation='relu'))\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.5665 - accuracy: 0.8362 - val_loss: 0.3347 - val_accuracy: 0.9047\n",
      "epoch: 0,history_callback.0.904699981212616\n",
      "0.904699981212616\n"
     ]
    }
   ],
   "source": [
    "history_callback = model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=epoch, batch_size=100,\n",
    "                             callbacks=[cbk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = np.array(history_callback.history['val_accuracy'])\n",
    "val_loss =  np.array(history_callback.history['val_loss'])\n",
    "accuracy =  np.array(history_callback.history['accuracy'])\n",
    "loss =  np.array(history_callback.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1caa6c16e48>,\n",
       " <matplotlib.lines.Line2D at 0x1caa6c1dd48>,\n",
       " <matplotlib.lines.Line2D at 0x1caa6c1df08>,\n",
       " <matplotlib.lines.Line2D at 0x1caa6c27108>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.0, epoch, 1)\n",
    "plt.plot(x,val_accuracy,x,accuracy,x,loss,x,val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kr.models.Sequential()\n",
    "model.add(kr.layers.Dense(units=512, input_dim=784, activation='relu'))\n",
    "model.add(kr.layers.Dropout(0.01))\n",
    "model.add(kr.layers.Dense(units=98, activation='relu'))\n",
    "model.add(kr.layers.Dropout(0.1))\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.6029 - accuracy: 0.8127 - val_loss: 0.3369 - val_accuracy: 0.8985\n",
      "epoch: 0,history_callback.0.8985000252723694\n",
      "0.8985000252723694\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "history_callback = model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=epoch, batch_size=100\n",
    "                             , callbacks=[cbk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy = np.array(history_callback.history['val_accuracy'])\n",
    "val_loss =  np.array(history_callback.history['val_loss'])\n",
    "accuracy =  np.array(history_callback.history['accuracy'])\n",
    "loss =  np.array(history_callback.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cce20ff648>,\n",
       " <matplotlib.lines.Line2D at 0x1cce2102608>,\n",
       " <matplotlib.lines.Line2D at 0x1cce21027c8>,\n",
       " <matplotlib.lines.Line2D at 0x1cce2102988>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x = np.arange(0.0, epoch, 1)\n",
    "plt.plot(x,val_accuracy,x,accuracy,x,loss,x,val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_13_input to have 4 dimensions, but got array with shape (10000, 784)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-539b1b0b5424>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model1.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1347\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1350\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_13_input to have 4 dimensions, but got array with shape (10000, 784)"
     ]
    }
   ],
   "source": [
    "score = kr.models.load_model('./model1.h5').evaluate(x_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(train_img_total,col,row,1)\n",
    "x_test = x_test.reshape(test_img_total,col,row,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kr.models.Sequential()\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(7, 7),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(7, 7),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "model.add(kr.layers.Conv2D(128,kernel_size=(5, 5),activation='relu'))\n",
    "model.add(kr.layers.Conv2D(256,kernel_size=(3, 3),activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "model.add(kr.layers.Flatten())\n",
    "model.add(kr.layers.Dropout(0.25))\n",
    "model.add(kr.layers.Dense(units=98, activation='relu'))\n",
    "model.add(kr.layers.Dropout(0.1))\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.2193 - accuracy: 0.9301 - val_loss: 0.0546 - val_accuracy: 0.9828\n",
      "epoch: 0,history_callback.0.9828000068664551\n",
      "0.9828000068664551\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "history_callback = model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=epoch, batch_size=100\n",
    "                             , callbacks=[cbk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04757987779821233, 0.9961000084877014]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = kr.models.load_model('./model1.h5').evaluate(x_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = kr.models.Sequential()\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(7, 7),activation='relu',input_shape=(28,28,1)))\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(7, 7),activation='relu',input_shape=(28,28,1)))\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "model.add(kr.layers.Conv2D(128,kernel_size=(5, 5),activation='relu'))\n",
    "kr.layers.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(256,kernel_size=(3, 3),activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "model.add(kr.layers.Flatten())\n",
    "model.add(kr.layers.Dropout(0.25))\n",
    "model.add(kr.layers.Dense(units=98, activation='relu'))\n",
    "model.add(kr.layers.Dropout(0.1))\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.2160 - accuracy: 0.9311 - val_loss: 0.0476 - val_accuracy: 0.9853\n",
      "epoch: 0,history_callback.0.9853000044822693\n",
      "0.9853000044822693\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "history_callback = model.fit(x_train, y_train, validation_data=(x_test,y_test), epochs=epoch, batch_size=100\n",
    "                             , callbacks=[cbk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04757987779821233, 0.9961000084877014]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = kr.models.load_model('./model1.h5').evaluate(x_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 22, 22, 64)        3200      \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 16, 16, 64)        200768    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 2, 2, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 706,634\n",
      "Trainable params: 706,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = kr.models.Sequential()\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(7, 7),activation='relu',input_shape=(28,28,1)))\n",
    "kr.layers.normalization.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.Conv2D(64,kernel_size=(7, 7),activation='relu',input_shape=(28,28,1)))\n",
    "kr.layers.normalization.BatchNormalization(axis=-1)\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "model.add(kr.layers.Conv2D(128,kernel_size=(5, 5),activation='relu'))\n",
    "model.add(kr.layers.Conv2D(256,kernel_size=(3, 3),activation='relu'))\n",
    "model.add(kr.layers.MaxPooling2D(pool_size=(2, 2),))\n",
    "model.add(kr.layers.Dropout(0.25))\n",
    "model.add(kr.layers.Flatten())\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))\n",
    "model.compile(loss=kr.losses.categorical_crossentropy,optimizer='adadelta',metrics=['accuracy'])\n",
    "model.summary()\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = gen.flow(x_train, y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(x_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "937/937 [==============================] - 11s 11ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 3.7253e-09 - val_accuracy: 0.9944\n",
      "epoch: 0,history_callback.0.9943910241127014\n",
      "0.9944000244140625\n",
      "Epoch 2/10\n",
      "937/937 [==============================] - 12s 12ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 1.3038e-07 - val_accuracy: 0.9950\n",
      "epoch: 1,history_callback.0.9949678182601929\n",
      "0.9950000047683716\n",
      "Epoch 3/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 6.8649e-06 - val_accuracy: 0.9945\n",
      "epoch: 2,history_callback.0.9944645762443542\n",
      "0.9944999814033508\n",
      "Epoch 4/10\n",
      "937/937 [==============================] - 11s 11ms/step - loss: 0.0111 - accuracy: 0.9975 - val_loss: 3.4880e-05 - val_accuracy: 0.9948\n",
      "epoch: 3,history_callback.0.9947665333747864\n",
      "0.9947999715805054\n",
      "Epoch 5/10\n",
      "937/937 [==============================] - 11s 12ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 5.9605e-08 - val_accuracy: 0.9951\n",
      "epoch: 4,history_callback.0.9950684309005737\n",
      "0.995199978351593\n",
      "Epoch 6/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.0000e+00 - val_accuracy: 0.9949\n",
      "epoch: 5,history_callback.0.9948671460151672\n",
      "0.9948999881744385\n",
      "Epoch 7/10\n",
      "937/937 [==============================] - 11s 11ms/step - loss: 0.0108 - accuracy: 0.9978 - val_loss: 7.4506e-09 - val_accuracy: 0.9956\n",
      "epoch: 6,history_callback.0.9955716729164124\n",
      "0.9955999851226807\n",
      "Epoch 8/10\n",
      "937/937 [==============================] - 11s 12ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 1.4901e-08 - val_accuracy: 0.9948\n",
      "epoch: 7,history_callback.0.9947665333747864\n",
      "0.9950000047683716\n",
      "Epoch 9/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 6.0282e-06 - val_accuracy: 0.9948\n",
      "epoch: 8,history_callback.0.9947665333747864\n",
      "0.9945999979972839\n",
      "Epoch 10/10\n",
      "937/937 [==============================] - 10s 11ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 1.2090e-04 - val_accuracy: 0.9950\n",
      "epoch: 9,history_callback.0.9949678182601929\n",
      "0.9948999881744385\n"
     ]
    }
   ],
   "source": [
    "epoch =10\n",
    "history_callback= model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=epoch, \n",
    "                    validation_data=test_generator, validation_steps=10000//64, callbacks=[cbk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.035182639097951635, 0.9958000183105469]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = kr.models.load_model('./model7.h5').evaluate(x_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
